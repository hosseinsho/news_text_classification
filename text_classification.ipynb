{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "name": "text_classification.ipynb",
   "provenance": [],
   "collapsed_sections": []
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  },
  "gpuClass": "standard",
  "accelerator": "GPU",
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "69a9a172ec824bd0be96bafb7d5141c9": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_dd1980cde61b44ffa8b1e231a6217e79",
       "IPY_MODEL_6df314219d4c47b0832b8fdcb345d2ad",
       "IPY_MODEL_93f504d1867148c3a3fe6804264b9e04"
      ],
      "layout": "IPY_MODEL_88e4095a14d24b4081db3113621d7188"
     }
    },
    "dd1980cde61b44ffa8b1e231a6217e79": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_33acc2ad7eab4b35a63b2b6b99fe64fc",
      "placeholder": "​",
      "style": "IPY_MODEL_b5c8f718ff41422e9bb3d43cb9031789",
      "value": "Downloading: 100%"
     }
    },
    "6df314219d4c47b0832b8fdcb345d2ad": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_8c88be50b22948a2be042531fba300dc",
      "max": 1198122,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_25198a55d753403eb68578e90e063d55",
      "value": 1198122
     }
    },
    "93f504d1867148c3a3fe6804264b9e04": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_b25a128a64424255b6381a479d6c011a",
      "placeholder": "​",
      "style": "IPY_MODEL_92a5feb5f0514c2582be3e05e6364b27",
      "value": " 1.14M/1.14M [00:00&lt;00:00, 2.73MB/s]"
     }
    },
    "88e4095a14d24b4081db3113621d7188": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "33acc2ad7eab4b35a63b2b6b99fe64fc": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b5c8f718ff41422e9bb3d43cb9031789": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "8c88be50b22948a2be042531fba300dc": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "25198a55d753403eb68578e90e063d55": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "b25a128a64424255b6381a479d6c011a": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "92a5feb5f0514c2582be3e05e6364b27": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "e91ca4b503b747708f0b776e0f1cf1cd": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_29f0278f33894e2696160ff9bde6cea6",
       "IPY_MODEL_c72bd1f870314025a76f9eae5eac7cad",
       "IPY_MODEL_fad68fbb47c64db5aefd890979bcf8e7"
      ],
      "layout": "IPY_MODEL_96b72f1f18734a2ba436d959c001fc66"
     }
    },
    "29f0278f33894e2696160ff9bde6cea6": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_3b0750f469014c9f88ce7dc9311af82f",
      "placeholder": "​",
      "style": "IPY_MODEL_84c047bd7b5f44f295c84d97bc88b885",
      "value": "Downloading: 100%"
     }
    },
    "c72bd1f870314025a76f9eae5eac7cad": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_a8a315ef5892430599048a6dd2ed881e",
      "max": 440,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_8f494b4caacb459f9b77b791c16db11c",
      "value": 440
     }
    },
    "fad68fbb47c64db5aefd890979bcf8e7": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_a36aa4a8c3a7453985250c8d1ac43501",
      "placeholder": "​",
      "style": "IPY_MODEL_8d2a89950f554d73a71c4a8b5ffc4abe",
      "value": " 440/440 [00:00&lt;00:00, 10.6kB/s]"
     }
    },
    "96b72f1f18734a2ba436d959c001fc66": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "3b0750f469014c9f88ce7dc9311af82f": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "84c047bd7b5f44f295c84d97bc88b885": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "a8a315ef5892430599048a6dd2ed881e": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "8f494b4caacb459f9b77b791c16db11c": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "a36aa4a8c3a7453985250c8d1ac43501": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "8d2a89950f554d73a71c4a8b5ffc4abe": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    }
   }
  }
 },
 "cells": [
  {
   "cell_type": "code",
   "source": [
    "!pip3 install transformers sentencepiece hazm clean-text[gpl]\n",
    "!pip install pyyaml==5.4.1"
   ],
   "metadata": {
    "id": "-VaKhQoMNj0B"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wO-D2RrsH4HI"
   },
   "outputs": [],
   "source": [
    "!gdown 1D3yt99D0GcCRCbdKbUQGxbqjkeh91hTg"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "!unrar x hamshahri.rar\n",
    "!cp /content/hamshahriold/Corpus/Hamshahri-Categories.txt /content/\n",
    "!unzip /content/hamshahriold/Corpus/Hamshahri-Corpus.zip\n",
    "!unzip /content/hamshahriold/Corpus/PersianStopWords.zip"
   ],
   "metadata": {
    "id": "RGVwf_ntKfVa"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import hazm\n",
    "\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "import tensorflow as tf\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.utils import shuffle\n",
    "from tqdm.notebook import tqdm\n",
    "from transformers import AutoConfig, AutoTokenizer, TFAutoModel, AutoModel, DataCollatorWithPadding\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Save data to csv file"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# [[DID value, Date value, CAT, text]]\n",
    "corpus = []\n",
    "tmp_text = \" \"\n",
    "tmp_values = []\n",
    "c = 0\n",
    "with open('Hamshahri-Corpus.txt', \"rb\") as file:\n",
    "  for line in file:\n",
    "    line = line.decode(\"UTF-8\")\n",
    "    if \".DID\" in line:\n",
    "      # some news are abnormal lenght and they are low in number(about 1000)\n",
    "      if len(tmp_text.split(' ')) < 2500:\n",
    "        tmp_values.append(tmp_text)\n",
    "        corpus.append(tmp_values)\n",
    "      tmp_text = \"\"\n",
    "      tmp_values = []\n",
    "      tmp_values.append(line.replace(\".DID\\t\", \"\").replace(\"\\r\\n\",\"\"))\n",
    "    elif \".Date\" in line:\n",
    "      tmp_values.append(line.replace(\".Date\\t\", \"\").replace(\"\\r\\n\",\"\").replace(\"\\\\\", \"/\"))\n",
    "    elif \".Cat\" in line:\n",
    "      tmp_values.append(line.replace(\".Cat\\t\", \"\").replace(\"\\r\\n\",\"\"))\n",
    "    else:\n",
    "      tmp_text += (line.strip() + \" \")\n",
    "corpus.pop(0)\n",
    "len(corpus)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df = pd.DataFrame(corpus, columns=['DID', 'date', 'cat', 'text'])\n",
    "df"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df.to_csv(\"dataset.csv\", date_format='%Y%m%d')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#preprocessing"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### stopwords"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df = df[['text', 'cat']]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# stop word\n",
    "stop_words_list = []\n",
    "with open('PersianStopWords.txt', \"rb\") as file:\n",
    "  for line in file:\n",
    "    stop_words_list.append(line.decode(\"UTF-8\").replace('\\r\\n', \"\"))\n",
    "\n",
    "for idx, txt in enumerate(df[\"text\"]):\n",
    "  word_tokenized =  hazm.word_tokenize(txt)\n",
    "  cps = \"\"\n",
    "  for word in word_tokenized:\n",
    "    if word not in stop_words_list:\n",
    "      cps += word + \" \"\n",
    "      \n",
    "  df.loc[idx].at['text'] = cps\n",
    "  if idx % 30000 == 0:\n",
    "    print(idx, \"numbers cleaned\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Normalization\n",
    "The text have different lengths based on words! Detecting the most normal range could help us find the maximum length of the sequences for the preprocessing step"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# calculate the length of text based on their words\n",
    "df['text_len_by_words'] = df['text'].apply(lambda t: len(hazm.word_tokenize(t)))\n",
    "min_max_len = df[\"text_len_by_words\"].min(), df[\"text_len_by_words\"].max()\n",
    "print(f'Min: {min_max_len[0]} \\tMax: {min_max_len[1]}')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def data_gl_than(data, less_than=100.0, greater_than=0.0, col='text_len_by_words'):\n",
    "    data_length = data[col].values\n",
    "    data_glt = sum([1 for length in data_length if greater_than < length <= less_than])\n",
    "    data_glt_rate = (data_glt / len(data_length)) * 100\n",
    "    print(f'Texts with word length of greater than {greater_than} and less than {less_than} includes {data_glt_rate:.2f}% of the whole!')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "minlim, maxlim = 10, 1000\n",
    "data_gl_than(df, maxlim, minlim)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# remove text with the length of fewer than minlim words and more than maxlim\n",
    "df['text_len_by_words'] = df['text_len_by_words'].apply(lambda len_t: len_t if minlim <= len_t else None)\n",
    "df = df.dropna(subset=['text_len_by_words'])\n",
    "df = df.reset_index(drop=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "fig = go.Figure()\n",
    "\n",
    "fig.add_trace(go.Histogram(\n",
    "    x=df['text_len_by_words']\n",
    "))\n",
    "\n",
    "fig.update_layout(\n",
    "    title_text='Distribution of word counts within text',\n",
    "    xaxis_title_text='Word Count',\n",
    "    yaxis_title_text='Frequency',\n",
    "    bargap=0.2,\n",
    "    bargroupgap=0.2)\n",
    "\n",
    "fig.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "int(np.mean(df['text_len_by_words']))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "fig = go.Figure()\n",
    "\n",
    "groupby_cat = df.groupby('cat')['cat'].count()\n",
    "\n",
    "fig.add_trace(go.Bar(\n",
    "    x=list(groupby_cat.index),\n",
    "    y=groupby_cat.tolist(),\n",
    "    text=groupby_cat.tolist(),\n",
    "    textposition='auto'\n",
    "))\n",
    "\n",
    "fig.update_layout(\n",
    "    title_text='Distribution of rate within text',\n",
    "    xaxis_title_text='Rate',\n",
    "    yaxis_title_text='Frequency',\n",
    "    bargap=0.2,\n",
    "    bargroupgap=0.2)\n",
    "\n",
    "fig.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### balance data which their cats are under 1000 instances"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "group_cats = list(groupby_cat.index)\n",
    "group_values = list(groupby_cat.values)\n",
    "remove_cats = []\n",
    "for idx, cat in enumerate(group_cats):\n",
    "  if group_values[idx] < 1000:\n",
    "    remove_cats.append(cat)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df['cat'] = df['cat'].apply(lambda cat: None if cat in remove_cats else cat)\n",
    "df = df.dropna(subset=['cat'])\n",
    "df = df.reset_index(drop=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "labels = list(sorted(df['cat'].unique()))\n",
    "print(f'We have #{len(labels)}: {labels}')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Train,Test split"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df['cat_id'] = df['cat'].apply(lambda t: labels.index(t))\n",
    "train, test = train_test_split(df, test_size=0.1, random_state=1, stratify=df['cat'])\n",
    "train, valid = train_test_split(train, test_size=0.1, random_state=1, stratify=train['cat'])\n",
    "\n",
    "train = train.reset_index(drop=True)\n",
    "valid = valid.reset_index(drop=True)\n",
    "test = test.reset_index(drop=True)\n",
    "\n",
    "x_train, y_train = train['text'].values.tolist(), train['cat_id'].values.tolist()\n",
    "x_valid, y_valid = valid['text'].values.tolist(), valid['cat_id'].values.tolist()\n",
    "x_test, y_test = test['text'].values.tolist(), test['cat_id'].values.tolist()\n",
    "\n",
    "print(len(x_train))\n",
    "print(len(x_valid))\n",
    "print(len(x_test))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#Model loading\n",
    "the BERT model input is a combination of 3 embeddings.\n",
    "- Token embeddings: WordPiece token vocabulary (WordPiece is another word segmentation algorithm, similar to BPE)\n",
    "- Segment embeddings: for pair sentences [A-B] marked as $E_A$ or $E_B$ mean that it belongs to the first sentence or the second one.\n",
    "- Position embeddings: specify the position of words in a sentence"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from transformers import BertConfig, BertTokenizer\n",
    "from transformers import TFBertModel, TFBertForSequenceClassification, BertForSequenceClassification\n",
    "from transformers import glue_convert_examples_to_features\n",
    "\n",
    "import tensorflow as tf"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# general config\n",
    "MAX_LEN = 128\n",
    "TRAIN_BATCH_SIZE = 32\n",
    "VALID_BATCH_SIZE = 32\n",
    "TEST_BATCH_SIZE = 32\n",
    "\n",
    "EPOCHS = 3\n",
    "EEVERY_EPOCH = 1000\n",
    "LEARNING_RATE = 5e-3\n",
    "CLIP = 0.0\n",
    "\n",
    "MODEL_NAME_OR_PATH = 'HooshvareLab/bert-fa-base-uncased'\n",
    "OUTPUT_PATH = '/content/news_classification.bin'\n",
    "\n",
    "os.makedirs(os.path.dirname(OUTPUT_PATH), exist_ok=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "label2id = {label: i for i, label in enumerate(labels)}\n",
    "id2label = {v: k for k, v in label2id.items()}\n",
    "\n",
    "print(f'label2id: {label2id}')\n",
    "print(f'id2label: {id2label}')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained(MODEL_NAME_OR_PATH)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#Input Embeddings / Dataset"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "class InputExample:\n",
    "    \"\"\" A single example for simple sequence classification. \"\"\"\n",
    "\n",
    "    def __init__(self, guid, text_a, text_b=None, label=None):\n",
    "        \"\"\" Constructs a InputExample. \"\"\"\n",
    "        self.guid = guid\n",
    "        self.text_a = text_a\n",
    "        self.text_b = text_b\n",
    "        self.label = label\n",
    "\n",
    "\n",
    "def make_examples(tokenizer, x, y=None, maxlen=MAX_LEN, output_mode=\"classification\", is_tf_dataset=True):\n",
    "    examples = []\n",
    "    y = y if isinstance(y, list) or isinstance(y, np.ndarray) else [None] * len(x)\n",
    "\n",
    "    for i, (_x, _y) in tqdm(enumerate(zip(x, y)), position=0, total=len(x)):\n",
    "        guid = \"%s\" % i\n",
    "        label = int(_y)\n",
    "        \n",
    "        if isinstance(_x, str):\n",
    "            text_a = _x\n",
    "            text_b = None\n",
    "        else:\n",
    "            assert len(_x) == 2\n",
    "            text_a = _x[0]\n",
    "            text_b = _x[1]\n",
    "        \n",
    "        examples.append(InputExample(guid=guid, text_a=text_a, text_b=text_b, label=label))\n",
    "    \n",
    "    features = glue_convert_examples_to_features(\n",
    "        examples, \n",
    "        tokenizer, \n",
    "        maxlen, \n",
    "        output_mode=output_mode, \n",
    "        label_list=list(np.unique(y)))\n",
    "\n",
    "    all_input_ids = []\n",
    "    all_attention_masks = []\n",
    "    all_token_type_ids = []\n",
    "    all_labels = []\n",
    "\n",
    "    for f in tqdm(features, position=0, total=len(examples)):\n",
    "        if is_tf_dataset:\n",
    "            all_input_ids.append(tf.constant(f.input_ids))\n",
    "            all_attention_masks.append(tf.constant(f.attention_mask))\n",
    "            all_token_type_ids.append(tf.constant(f.token_type_ids))\n",
    "            all_labels.append(tf.constant(f.label))\n",
    "        else:\n",
    "            all_input_ids.append(f.input_ids)\n",
    "            all_attention_masks.append(f.attention_mask)\n",
    "            all_token_type_ids.append(f.token_type_ids)\n",
    "            all_labels.append(f.label)\n",
    "\n",
    "    if is_tf_dataset:\n",
    "        dataset = tf.data.Dataset.from_tensor_slices(({\n",
    "            'input_ids': all_input_ids,\n",
    "            'attention_mask': all_attention_masks,\n",
    "            'token_type_ids': all_token_type_ids\n",
    "        }, all_labels))\n",
    "\n",
    "        return dataset, features\n",
    "    \n",
    "    xdata = [np.array(all_input_ids), np.array(all_attention_masks), np.array(all_token_type_ids)]\n",
    "    ydata = all_labels\n",
    "\n",
    "    return [xdata, ydata], features"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "train_dataset_base, train_examples = make_examples(tokenizer, x_train, y_train, maxlen=MAX_LEN)\n",
    "valid_dataset_base, valid_examples = make_examples(tokenizer, x_valid, y_valid, maxlen=MAX_LEN)\n",
    "\n",
    "test_dataset_base, test_examples = make_examples(tokenizer, x_test, y_test, maxlen=MAX_LEN)\n",
    "[xtest, ytest], test_examples = make_examples(tokenizer, x_test, y_test, maxlen=MAX_LEN, is_tf_dataset=False)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "for value in train_dataset_base.take(1):\n",
    "    print(f'     input_ids: {value[0][\"input_ids\"]}')\n",
    "    print(f'attention_mask: {value[0][\"attention_mask\"]}')\n",
    "    print(f'token_type_ids: {value[0][\"token_type_ids\"]}')\n",
    "    print(f'        target: {value[1]}')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def get_training_dataset(dataset, batch_size, buffer_size):\n",
    "    dataset = dataset.shuffle(2048)\n",
    "    dataset = dataset.batch(batch_size)\n",
    "\n",
    "    return dataset\n",
    "\n",
    "def get_validation_dataset(dataset, batch_size):\n",
    "    dataset = dataset.batch(batch_size)\n",
    "\n",
    "    return dataset"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "train_dataset = get_training_dataset(train_dataset_base, TRAIN_BATCH_SIZE, len(train_examples))\n",
    "valid_dataset = get_validation_dataset(valid_dataset_base, VALID_BATCH_SIZE)\n",
    "\n",
    "train_steps = len(train_examples) // TRAIN_BATCH_SIZE\n",
    "valid_steps = len(valid_examples) // VALID_BATCH_SIZE\n",
    "\n",
    "train_steps, valid_steps"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## model"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "config = BertConfig.from_pretrained(\n",
    "    MODEL_NAME_OR_PATH, **{\n",
    "        'label2id': label2id,\n",
    "        'id2label': id2label,\n",
    "    })\n",
    "print(config.to_json_string())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from transformers import TFBertModel, TFBertForSequenceClassification, BertForSequenceClassification\n",
    "from transformers import TFAutoModel, AutoModel, AutoModelForTokenClassification\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def build_model(model_name, config, learning_rate=3e-5):\n",
    "    model = TFBertForSequenceClassification.from_pretrained(model_name, config=config)\n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)\n",
    "    loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "    metric = tf.keras.metrics.SparseCategoricalAccuracy('accuracy')\n",
    "    model.compile(optimizer=optimizer, loss=loss, metrics=[metric])\n",
    "\n",
    "    return model"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model = build_model(MODEL_NAME_OR_PATH, config, learning_rate=LEARNING_RATE)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "r = model.fit(\n",
    "    train_dataset,\n",
    "    validation_data=valid_dataset,\n",
    "    steps_per_epoch=train_steps,\n",
    "    validation_steps=valid_steps,\n",
    "    epochs=EPOCHS,\n",
    "    verbose=1)\n",
    "\n",
    "final_accuracy = r.history['val_accuracy']\n",
    "print('FINAL ACCURACY MEAN: ', np.mean(final_accuracy))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# save the model\n",
    "\n",
    "model.save_pretrained(os.path.dirname(OUTPUT_PATH))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Evaluation / Prediction"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "ev = model.evaluate(test_dataset_base.batch(TEST_BATCH_SIZE))\n",
    "print()\n",
    "print(f'Evaluation: {ev}')\n",
    "print()\n",
    "\n",
    "predictions = model.predict(xtest)\n",
    "ypred = predictions[0].argmax(axis=-1).tolist()\n",
    "\n",
    "print()\n",
    "print(classification_report(ytest, ypred, target_names=labels))\n",
    "print()\n",
    "\n",
    "print(f'F1: {f1_score(ytest, ypred, average=\"weighted\")}')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#Model loading\n",
    "the BERT model input is a combination of 3 embeddings.\n",
    "- Token embeddings: WordPiece token vocabulary (WordPiece is another word segmentation algorithm, similar to BPE)\n",
    "- Segment embeddings: for pair sentences [A-B] marked as $E_A$ or $E_B$ mean that it belongs to the first sentence or the second one.\n",
    "- Position embeddings: specify the position of words in a sentence"
   ],
   "metadata": {
    "id": "FfEsr4XoWZdO"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "from transformers import BertConfig, BertTokenizer\n",
    "from transformers import TFBertModel, TFBertForSequenceClassification, BertForSequenceClassification\n",
    "from transformers import glue_convert_examples_to_features\n",
    "\n",
    "import tensorflow as tf"
   ],
   "metadata": {
    "id": "h63S0kqHD17R"
   },
   "execution_count": 21,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# general config\n",
    "MAX_LEN = 128\n",
    "TRAIN_BATCH_SIZE = 32\n",
    "VALID_BATCH_SIZE = 32\n",
    "TEST_BATCH_SIZE = 32\n",
    "\n",
    "EPOCHS = 3\n",
    "EEVERY_EPOCH = 1000\n",
    "LEARNING_RATE = 5e-3\n",
    "CLIP = 0.0\n",
    "\n",
    "MODEL_NAME_OR_PATH = 'HooshvareLab/bert-fa-base-uncased'\n",
    "OUTPUT_PATH = '/content/news_classification.bin'\n",
    "\n",
    "os.makedirs(os.path.dirname(OUTPUT_PATH), exist_ok=True)"
   ],
   "metadata": {
    "id": "V6rkBaUvD6fE"
   },
   "execution_count": 27,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "label2id = {label: i for i, label in enumerate(labels)}\n",
    "id2label = {v: k for k, v in label2id.items()}\n",
    "\n",
    "print(f'label2id: {label2id}')\n",
    "print(f'id2label: {id2label}')"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Z_5zPbozGal6",
    "outputId": "067c12bd-b612-440d-82cc-e13796a8ee70"
   },
   "execution_count": 28,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "label2id: {'adabh': 0, 'aeqts': 1, 'akhar': 2, 'ejtem': 3, 'elmfa': 4, 'elmif': 5, 'eqtes': 6, 'gozar': 7, 'gungn': 8, 'havad': 9, 'jvarz': 10, 'kharj': 11, 'maqal': 12, 'nnaft': 13, 'polig': 14, 'shahr': 15, 'shari': 16, 'shrst': 17, 'siasi': 18, 'soxan': 19, 'vrzsh': 20}\n",
      "id2label: {0: 'adabh', 1: 'aeqts', 2: 'akhar', 3: 'ejtem', 4: 'elmfa', 5: 'elmif', 6: 'eqtes', 7: 'gozar', 8: 'gungn', 9: 'havad', 10: 'jvarz', 11: 'kharj', 12: 'maqal', 13: 'nnaft', 14: 'polig', 15: 'shahr', 16: 'shari', 17: 'shrst', 18: 'siasi', 19: 'soxan', 20: 'vrzsh'}\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "tokenizer = BertTokenizer.from_pretrained(MODEL_NAME_OR_PATH)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 81,
     "referenced_widgets": [
      "69a9a172ec824bd0be96bafb7d5141c9",
      "dd1980cde61b44ffa8b1e231a6217e79",
      "6df314219d4c47b0832b8fdcb345d2ad",
      "93f504d1867148c3a3fe6804264b9e04",
      "88e4095a14d24b4081db3113621d7188",
      "33acc2ad7eab4b35a63b2b6b99fe64fc",
      "b5c8f718ff41422e9bb3d43cb9031789",
      "8c88be50b22948a2be042531fba300dc",
      "25198a55d753403eb68578e90e063d55",
      "b25a128a64424255b6381a479d6c011a",
      "92a5feb5f0514c2582be3e05e6364b27",
      "e91ca4b503b747708f0b776e0f1cf1cd",
      "29f0278f33894e2696160ff9bde6cea6",
      "c72bd1f870314025a76f9eae5eac7cad",
      "fad68fbb47c64db5aefd890979bcf8e7",
      "96b72f1f18734a2ba436d959c001fc66",
      "3b0750f469014c9f88ce7dc9311af82f",
      "84c047bd7b5f44f295c84d97bc88b885",
      "a8a315ef5892430599048a6dd2ed881e",
      "8f494b4caacb459f9b77b791c16db11c",
      "a36aa4a8c3a7453985250c8d1ac43501",
      "8d2a89950f554d73a71c4a8b5ffc4abe"
     ]
    },
    "id": "T_TFJtz_MvZ3",
    "outputId": "74dc7ad2-37e5-45f8-dcd0-e4e7e7212492"
   },
   "execution_count": 24,
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "Downloading:   0%|          | 0.00/1.14M [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "69a9a172ec824bd0be96bafb7d5141c9"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "Downloading:   0%|          | 0.00/440 [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "e91ca4b503b747708f0b776e0f1cf1cd"
      }
     },
     "metadata": {}
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "#Input Embeddings / Dataset"
   ],
   "metadata": {
    "id": "NkYyDap1H7AB"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "class InputExample:\n",
    "    \"\"\" A single example for simple sequence classification. \"\"\"\n",
    "\n",
    "    def __init__(self, guid, text_a, text_b=None, label=None):\n",
    "        \"\"\" Constructs a InputExample. \"\"\"\n",
    "        self.guid = guid\n",
    "        self.text_a = text_a\n",
    "        self.text_b = text_b\n",
    "        self.label = label\n",
    "\n",
    "\n",
    "def make_examples(tokenizer, x, y=None, maxlen=MAX_LEN, output_mode=\"classification\", is_tf_dataset=True):\n",
    "    examples = []\n",
    "    y = y if isinstance(y, list) or isinstance(y, np.ndarray) else [None] * len(x)\n",
    "\n",
    "    for i, (_x, _y) in tqdm(enumerate(zip(x, y)), position=0, total=len(x)):\n",
    "        guid = \"%s\" % i\n",
    "        label = int(_y)\n",
    "        \n",
    "        if isinstance(_x, str):\n",
    "            text_a = _x\n",
    "            text_b = None\n",
    "        else:\n",
    "            assert len(_x) == 2\n",
    "            text_a = _x[0]\n",
    "            text_b = _x[1]\n",
    "        \n",
    "        examples.append(InputExample(guid=guid, text_a=text_a, text_b=text_b, label=label))\n",
    "    \n",
    "    features = glue_convert_examples_to_features(\n",
    "        examples, \n",
    "        tokenizer, \n",
    "        maxlen, \n",
    "        output_mode=output_mode, \n",
    "        label_list=list(np.unique(y)))\n",
    "\n",
    "    all_input_ids = []\n",
    "    all_attention_masks = []\n",
    "    all_token_type_ids = []\n",
    "    all_labels = []\n",
    "\n",
    "    for f in tqdm(features, position=0, total=len(examples)):\n",
    "        if is_tf_dataset:\n",
    "            all_input_ids.append(tf.constant(f.input_ids))\n",
    "            all_attention_masks.append(tf.constant(f.attention_mask))\n",
    "            all_token_type_ids.append(tf.constant(f.token_type_ids))\n",
    "            all_labels.append(tf.constant(f.label))\n",
    "        else:\n",
    "            all_input_ids.append(f.input_ids)\n",
    "            all_attention_masks.append(f.attention_mask)\n",
    "            all_token_type_ids.append(f.token_type_ids)\n",
    "            all_labels.append(f.label)\n",
    "\n",
    "    if is_tf_dataset:\n",
    "        dataset = tf.data.Dataset.from_tensor_slices(({\n",
    "            'input_ids': all_input_ids,\n",
    "            'attention_mask': all_attention_masks,\n",
    "            'token_type_ids': all_token_type_ids\n",
    "        }, all_labels))\n",
    "\n",
    "        return dataset, features\n",
    "    \n",
    "    xdata = [np.array(all_input_ids), np.array(all_attention_masks), np.array(all_token_type_ids)]\n",
    "    ydata = all_labels\n",
    "\n",
    "    return [xdata, ydata], features"
   ],
   "metadata": {
    "id": "qVR67qBGH6nG"
   },
   "execution_count": 29,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "train_dataset_base, train_examples = make_examples(tokenizer, x_train, y_train, maxlen=MAX_LEN)\n",
    "valid_dataset_base, valid_examples = make_examples(tokenizer, x_valid, y_valid, maxlen=MAX_LEN)\n",
    "\n",
    "test_dataset_base, test_examples = make_examples(tokenizer, x_test, y_test, maxlen=MAX_LEN)\n",
    "[xtest, ytest], test_examples = make_examples(tokenizer, x_test, y_test, maxlen=MAX_LEN, is_tf_dataset=False)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34,
     "referenced_widgets": [
      "c84f39100b8e49e7b02442e4edbedfa2"
     ]
    },
    "id": "cLDichYiIIA7",
    "outputId": "36904056-17a1-495f-e644-2768d17e1eb1"
   },
   "execution_count": 30,
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "  0%|          | 0/14500 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "c84f39100b8e49e7b02442e4edbedfa2"
      }
     },
     "metadata": {}
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "for value in train_dataset_base.take(1):\n",
    "    print(f'     input_ids: {value[0][\"input_ids\"]}')\n",
    "    print(f'attention_mask: {value[0][\"attention_mask\"]}')\n",
    "    print(f'token_type_ids: {value[0][\"token_type_ids\"]}')\n",
    "    print(f'        target: {value[1]}')"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Xl8X8D8lI2Yg",
    "outputId": "27fea394-50b5-4163-c385-68c10b43a8dd"
   },
   "execution_count": 31,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "     input_ids: [    2     1  3229  2038  4906  7590  4963  2015  3501  2038     1  3912\n",
      "  5388  2038  2038  4443 27490  2038  4073 32694  3483     1  2897  5662\n",
      "  4115 27490  2011 10892  2956  4963  2015  3501  2038     1  3912  8568\n",
      "  3414  4906     1     1  5045  3381  2038  3326     1 14213  3148  2038\n",
      "  3764     1  3589     1     1  3543 11373 43166  5486  2038  3127 19682\n",
      "  3298  5388  2038  2038 20399  5301  2822 27490  2809  2038  3381  5301\n",
      "  2876 19006  4029  5985  4443 27490  2038  9923  2783  2976 27490 20749\n",
      "  3350  4863     1  5168 27490  5388  2038  2038 14489     1  3229  2038\n",
      "  4443 27490  2038  3434  4676  2038  2897     1  3229  2038     1  2991\n",
      "  3421  3733  3764     1  3470     1 14213  4004  3740 27490 54492  3127\n",
      " 19682  3298  5388  2038  2038  5824  9682     4]\n",
      "attention_mask: [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "token_type_ids: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "        target: 20\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "def get_training_dataset(dataset, batch_size, buffer_size):\n",
    "    dataset = dataset.shuffle(2048)\n",
    "    dataset = dataset.batch(batch_size)\n",
    "\n",
    "    return dataset\n",
    "\n",
    "def get_validation_dataset(dataset, batch_size):\n",
    "    dataset = dataset.batch(batch_size)\n",
    "\n",
    "    return dataset"
   ],
   "metadata": {
    "id": "j2L4lKPRKBm_"
   },
   "execution_count": 74,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "train_dataset = get_training_dataset(train_dataset_base, TRAIN_BATCH_SIZE, len(train_examples))\n",
    "valid_dataset = get_validation_dataset(valid_dataset_base, VALID_BATCH_SIZE)\n",
    "\n",
    "train_steps = len(train_examples) // TRAIN_BATCH_SIZE\n",
    "valid_steps = len(valid_examples) // VALID_BATCH_SIZE\n",
    "\n",
    "train_steps, valid_steps"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GBPjiTqfKElR",
    "outputId": "4a1b7e42-f55a-4a4d-d4b4-a990634f4d09"
   },
   "execution_count": 75,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(3670, 407)"
      ]
     },
     "metadata": {},
     "execution_count": 75
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## model"
   ],
   "metadata": {
    "id": "PCW6Y9CEKFJV"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "config = BertConfig.from_pretrained(\n",
    "    MODEL_NAME_OR_PATH, **{\n",
    "        'label2id': label2id,\n",
    "        'id2label': id2label,\n",
    "    })\n",
    "print(config.to_json_string())"
   ],
   "metadata": {
    "id": "fsiQcTv4THXD"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "from transformers import TFBertModel, TFBertForSequenceClassification, BertForSequenceClassification\n",
    "from transformers import TFAutoModel, AutoModel, AutoModelForTokenClassification\n"
   ],
   "metadata": {
    "id": "YA31feRSbJlX"
   },
   "execution_count": 35,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "def build_model(model_name, config, learning_rate=3e-5):\n",
    "    model = TFBertForSequenceClassification.from_pretrained(model_name, config=config)\n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)\n",
    "    loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "    metric = tf.keras.metrics.SparseCategoricalAccuracy('accuracy')\n",
    "    model.compile(optimizer=optimizer, loss=loss, metrics=[metric])\n",
    "\n",
    "    return model"
   ],
   "metadata": {
    "id": "x4PGpPpgKNvn"
   },
   "execution_count": 36,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "model = build_model(MODEL_NAME_OR_PATH, config, learning_rate=LEARNING_RATE)"
   ],
   "metadata": {
    "id": "BCe3vvQjKQYx"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "%%time\n",
    "\n",
    "r = model.fit(\n",
    "    train_dataset,\n",
    "    validation_data=valid_dataset,\n",
    "    steps_per_epoch=train_steps,\n",
    "    validation_steps=valid_steps,\n",
    "    epochs=EPOCHS,\n",
    "    verbose=1)\n",
    "\n",
    "final_accuracy = r.history['val_accuracy']\n",
    "print('FINAL ACCURACY MEAN: ', np.mean(final_accuracy))"
   ],
   "metadata": {
    "id": "4HbaWtrYKU8i"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# save the model\n",
    "\n",
    "model.save_pretrained(os.path.dirname(OUTPUT_PATH))"
   ],
   "metadata": {
    "id": "5LXsqHwzKapF"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Evaluation / Prediction"
   ],
   "metadata": {
    "id": "MnzeJQttKePD"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "ev = model.evaluate(test_dataset_base.batch(TEST_BATCH_SIZE))\n",
    "print()\n",
    "print(f'Evaluation: {ev}')\n",
    "print()\n",
    "\n",
    "predictions = model.predict(xtest)\n",
    "ypred = predictions[0].argmax(axis=-1).tolist()\n",
    "\n",
    "print()\n",
    "print(classification_report(ytest, ypred, target_names=labels))\n",
    "print()\n",
    "\n",
    "print(f'F1: {f1_score(ytest, ypred, average=\"weighted\")}')"
   ],
   "metadata": {
    "id": "i62KLqIFKiuZ"
   },
   "execution_count": null,
   "outputs": []
  }
 ]
}