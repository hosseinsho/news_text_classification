{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "name": "text_classification.ipynb",
   "provenance": [],
   "collapsed_sections": []
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  },
  "gpuClass": "standard"
 },
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "!pip3 install transformers sentencepiece hazm clean-text[gpl]\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "!gdown 1D3yt99D0GcCRCbdKbUQGxbqjkeh91hTg"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "!unrar x hamshahri.rar\n",
    "!cp /content/hamshahriold/Corpus/Hamshahri-Categories.txt /content/\n",
    "!unzip /content/hamshahriold/Corpus/Hamshahri-Corpus.zip\n",
    "!unzip /content/hamshahriold/Corpus/PersianStopWords.zip"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import hazm\n",
    "from transformers import AutoConfig, AutoTokenizer, TFAutoModel, AutoModel, DataCollatorWithPadding"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Save data to csv file"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# [[DID value, Date value, CAT, text]]\n",
    "corpus = []\n",
    "tmp_text = \" \"\n",
    "tmp_values = []\n",
    "c = 0\n",
    "with open('Hamshahri-Corpus.txt', \"rb\") as file:\n",
    "  for line in file:\n",
    "    line = line.decode(\"UTF-8\")\n",
    "    if \".DID\" in line:\n",
    "      if len(tmp_text.split(' ')) < 1000:\n",
    "        tmp_values.append(tmp_text)\n",
    "        corpus.append(tmp_values)\n",
    "      tmp_text = \"\"\n",
    "      tmp_values = []\n",
    "      tmp_values.append(line.replace(\".DID\\t\", \"\").replace(\"\\r\\n\",\"\"))\n",
    "    elif \".Date\" in line:\n",
    "      tmp_values.append(line.replace(\".Date\\t\", \"\").replace(\"\\r\\n\",\"\").replace(\"\\\\\", \"/\"))\n",
    "    elif \".Cat\" in line:\n",
    "      tmp_values.append(line.replace(\".Cat\\t\", \"\").replace(\"\\r\\n\",\"\"))\n",
    "    else:\n",
    "      tmp_text += (line.strip() + \" \")\n",
    "corpus.pop(0)\n",
    "len(corpus)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df = pd.DataFrame(corpus, columns=['DID', 'Date', 'Cat', 'Text'])\n",
    "df"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df.to_csv(\"dataset.csv\", date_format='%Y%m%d')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#preprocessing"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df = df[['Text', 'Cat']]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "x = 0\n",
    "y = 0\n",
    "z = 0\n",
    "for txt in df[\"Text\"]:\n",
    "  l = len(txt.split(\" \"))\n",
    "  if len(txt.split(\" \")) < 10:\n",
    "    z += 1\n",
    "    x = l\n",
    "    y=txt\n",
    "x\n",
    "z"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "y"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# stop word\n",
    "stop_words_list = []\n",
    "with open('PersianStopWords.txt', \"rb\") as file:\n",
    "  for line in file:\n",
    "    stop_words_list.append(line.decode(\"UTF-8\").replace('\\r\\n', \"\"))\n",
    "\n",
    "for idx, txt in enumerate(df[\"Text\"]):\n",
    "  word_tokenized =  hazm.word_tokenize(txt)\n",
    "  cps = \"\"\n",
    "  for word in word_tokenized:\n",
    "    if word not in stop_words_list:\n",
    "      cps += word + \" \"\n",
    "\n",
    "  df.loc[idx].at['Text'] = cps\n",
    "  if idx % 50000 == 0:\n",
    "    print(idx, \"numbers cleaned\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Normalization"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df['text_len_by_words'] = df['Text'].apply(lambda t: len(hazm.word_tokenize(t)))\n",
    "min_max_len = df[\"text_len_by_words\"].min(), df[\"text_len_by_words\"].max()\n",
    "print(f'Min: {min_max_len[0]} \\tMax: {min_max_len[1]}')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def data_gl_than(data, less_than=100.0, greater_than=0.0, col='text_len_by_words'):\n",
    "    data_length = data[col].values\n",
    "\n",
    "    data_glt = sum([1 for length in data_length if greater_than < length <= less_than])\n",
    "\n",
    "    data_glt_rate = (data_glt / len(data_length)) * 100\n",
    "\n",
    "    print(f'Texts with word length of greater than {greater_than} and less than {less_than} includes {data_glt_rate:.2f}% of the whole!')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "minlim, maxlim = 10, 500\n",
    "data_gl_than(df, maxlim, minlim)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# remove comments with the length of fewer than three words\n",
    "df['text_len_by_words'] = df['text_len_by_words'].apply(lambda len_t: len_t if minlim <= len_t <= maxlim else None)\n",
    "df = df.dropna(subset=['text_len_by_words'])\n",
    "df = df.reset_index(drop=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "min_max_len = df[\"text_len_by_words\"].min(), df[\"text_len_by_words\"].max()\n",
    "print(f'Min: {min_max_len[0]} \\tMax: {min_max_len[1]}')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "unique_cats = list(sorted(df['Cat'].unique()))\n",
    "print(f'We have #{len(unique_cats)}: {unique_cats}')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#Model loading"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model_repo = \"HooshvareLab/bert-fa-base-uncased-clf-persiannews\"\n",
    "config = AutoConfig.from_pretrained(model_repo)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_repo)\n",
    "model = AutoModel.from_pretrained(model_repo, num_labels=len(unique_cats))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model.config.max_length = 20"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def preprocess_function(examples):\n",
    "    return tokenizer(examples, truncation=True)\n",
    "cf[\"Text\"].map(preprocess_function)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "len(tokenizer(cf[\"Text\"][10], truncation=True, padding=True)['input_ids'])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "cf[\"Text\"][0]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import hazm\n",
    "from transformers import AutoConfig, AutoTokenizer, TFAutoModel, AutoModel, DataCollatorWithPadding"
   ],
   "metadata": {
    "id": "jGQXlUEUKh6a"
   },
   "execution_count": 80,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Save data to csv file"
   ],
   "metadata": {
    "id": "gbtClgxyBup5"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# [[DID value, Date value, CAT, text]]\n",
    "corpus = []\n",
    "tmp_text = \" \"\n",
    "tmp_values = []\n",
    "c = 0\n",
    "with open('Hamshahri-Corpus.txt', \"rb\") as file:\n",
    "  for line in file:\n",
    "    line = line.decode(\"UTF-8\")\n",
    "    if \".DID\" in line:\n",
    "      if len(tmp_text.split(' ')) < 1000:\n",
    "        tmp_values.append(tmp_text)\n",
    "        corpus.append(tmp_values)\n",
    "      tmp_text = \"\"\n",
    "      tmp_values = []\n",
    "      tmp_values.append(line.replace(\".DID\\t\", \"\").replace(\"\\r\\n\",\"\"))\n",
    "    elif \".Date\" in line:\n",
    "      tmp_values.append(line.replace(\".Date\\t\", \"\").replace(\"\\r\\n\",\"\").replace(\"\\\\\", \"/\"))\n",
    "    elif \".Cat\" in line:\n",
    "      tmp_values.append(line.replace(\".Cat\\t\", \"\").replace(\"\\r\\n\",\"\"))\n",
    "    else:\n",
    "      tmp_text += (line.strip() + \" \")\n",
    "corpus.pop(0)\n",
    "len(corpus)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_uf8frernAGE",
    "outputId": "97fde36b-7fc7-4909-c243-515f89a57657"
   },
   "execution_count": 17,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "150505"
      ]
     },
     "metadata": {},
     "execution_count": 17
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "df = pd.DataFrame(corpus, columns=['DID', 'Date', 'Cat', 'Text'])\n",
    "df"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "id": "-ReerbUf8C_W",
    "outputId": "7a30fc65-0d09-4aa3-be4a-2ba613f3b410"
   },
   "execution_count": 18,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "            DID      Date    Cat  \\\n",
       "0           1S1  75/04/02  adabh   \n",
       "1           2S1  75/04/02  adabh   \n",
       "2           3S1  75/04/02  adabh   \n",
       "3           5S1  75/04/02  elmfa   \n",
       "4           6S1  75/04/02  elmfa   \n",
       "...         ...       ...    ...   \n",
       "150500  60055S1  81/11/20  vrzsh   \n",
       "150501  60055S2  81/11/20  vrzsh   \n",
       "150502  60055S3  81/11/20  vrzsh   \n",
       "150503  60055S4  81/11/20  vrzsh   \n",
       "150504  60055S5  81/11/20  vrzsh   \n",
       "\n",
       "                                                     Text  \n",
       "0       جاودانگي در زندگي گروهي از طريق هنر نگاهي به ن...  \n",
       "1       رويدادهاي هنري جهان نمايشگاه هنر در خدمت ديكتا...  \n",
       "2       برديوار نگارخانه ها گالري گلستان: نمايشگاه طرح...  \n",
       "3       تخته سياه و غباري كه سترده نمي شود... اشاره; ب...  \n",
       "4       احتمال اعتصاب آموزگاران در جمهوري آذربايجان به...  \n",
       "...                                                   ...  \n",
       "150500  گره هاي كور كشتي باز مي؟ شود گروه ورزشي: با حض...  \n",
       "150501  نماينده فدراسيون جهاني واليبال از ايران هر نظر...  \n",
       "150502  شكست نامداران تكواندودر پيكارهاي برتر ليگ گروه...  \n",
       "150503  ورزشگاه بزرگ دانشگاه آزاد در تهران ساخته مي شو...  \n",
       "150504  رئيس فدراسيون پزشكي انتخاب شد گروه ورزشي: مجمع...  \n",
       "\n",
       "[150505 rows x 4 columns]"
      ],
      "text/html": [
       "\n",
       "  <div id=\"df-97c69920-be5d-4ae8-92ed-f8a48f426e24\">\n",
       "    <div class=\"colab-df-container\">\n",
       "      <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DID</th>\n",
       "      <th>Date</th>\n",
       "      <th>Cat</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1S1</td>\n",
       "      <td>75/04/02</td>\n",
       "      <td>adabh</td>\n",
       "      <td>جاودانگي در زندگي گروهي از طريق هنر نگاهي به ن...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2S1</td>\n",
       "      <td>75/04/02</td>\n",
       "      <td>adabh</td>\n",
       "      <td>رويدادهاي هنري جهان نمايشگاه هنر در خدمت ديكتا...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3S1</td>\n",
       "      <td>75/04/02</td>\n",
       "      <td>adabh</td>\n",
       "      <td>برديوار نگارخانه ها گالري گلستان: نمايشگاه طرح...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5S1</td>\n",
       "      <td>75/04/02</td>\n",
       "      <td>elmfa</td>\n",
       "      <td>تخته سياه و غباري كه سترده نمي شود... اشاره; ب...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6S1</td>\n",
       "      <td>75/04/02</td>\n",
       "      <td>elmfa</td>\n",
       "      <td>احتمال اعتصاب آموزگاران در جمهوري آذربايجان به...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150500</th>\n",
       "      <td>60055S1</td>\n",
       "      <td>81/11/20</td>\n",
       "      <td>vrzsh</td>\n",
       "      <td>گره هاي كور كشتي باز مي؟ شود گروه ورزشي: با حض...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150501</th>\n",
       "      <td>60055S2</td>\n",
       "      <td>81/11/20</td>\n",
       "      <td>vrzsh</td>\n",
       "      <td>نماينده فدراسيون جهاني واليبال از ايران هر نظر...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150502</th>\n",
       "      <td>60055S3</td>\n",
       "      <td>81/11/20</td>\n",
       "      <td>vrzsh</td>\n",
       "      <td>شكست نامداران تكواندودر پيكارهاي برتر ليگ گروه...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150503</th>\n",
       "      <td>60055S4</td>\n",
       "      <td>81/11/20</td>\n",
       "      <td>vrzsh</td>\n",
       "      <td>ورزشگاه بزرگ دانشگاه آزاد در تهران ساخته مي شو...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150504</th>\n",
       "      <td>60055S5</td>\n",
       "      <td>81/11/20</td>\n",
       "      <td>vrzsh</td>\n",
       "      <td>رئيس فدراسيون پزشكي انتخاب شد گروه ورزشي: مجمع...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>150505 rows × 4 columns</p>\n",
       "</div>\n",
       "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-97c69920-be5d-4ae8-92ed-f8a48f426e24')\"\n",
       "              title=\"Convert this dataframe to an interactive table.\"\n",
       "              style=\"display:none;\">\n",
       "        \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
       "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
       "  </svg>\n",
       "      </button>\n",
       "      \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      flex-wrap:wrap;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "      <script>\n",
       "        const buttonEl =\n",
       "          document.querySelector('#df-97c69920-be5d-4ae8-92ed-f8a48f426e24 button.colab-df-convert');\n",
       "        buttonEl.style.display =\n",
       "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "        async function convertToInteractive(key) {\n",
       "          const element = document.querySelector('#df-97c69920-be5d-4ae8-92ed-f8a48f426e24');\n",
       "          const dataTable =\n",
       "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                     [key], {});\n",
       "          if (!dataTable) return;\n",
       "\n",
       "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "            + ' to learn more about interactive tables.';\n",
       "          element.innerHTML = '';\n",
       "          dataTable['output_type'] = 'display_data';\n",
       "          await google.colab.output.renderOutput(dataTable, element);\n",
       "          const docLink = document.createElement('div');\n",
       "          docLink.innerHTML = docLinkHtml;\n",
       "          element.appendChild(docLink);\n",
       "        }\n",
       "      </script>\n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ]
     },
     "metadata": {},
     "execution_count": 18
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "df.to_csv(\"dataset.csv\", date_format='%Y%m%d')"
   ],
   "metadata": {
    "id": "d5EvzvYk9Mc-"
   },
   "execution_count": 7,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "#preprocessing"
   ],
   "metadata": {
    "id": "ioM_GFTxMraN"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "df = df[['Text', 'Cat']]"
   ],
   "metadata": {
    "id": "G2WHj1bx_e-k"
   },
   "execution_count": 19,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "x = 0\n",
    "y = 0\n",
    "z = 0\n",
    "for txt in df[\"Text\"]:\n",
    "  l = len(txt.split(\" \"))\n",
    "  if len(txt.split(\" \")) < 10:\n",
    "    z += 1\n",
    "    x = l\n",
    "    y=txt\n",
    "x\n",
    "z"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2MTsy1rpedWN",
    "outputId": "73d88616-ed96-4118-8619-60cd8b894e22"
   },
   "execution_count": 57,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "2358"
      ]
     },
     "metadata": {},
     "execution_count": 57
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "y"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "id": "zcEHSQptfqan",
    "outputId": "66b47318-82fc-4d5e-85d9-c77e8f752696"
   },
   "execution_count": 53,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'فيلمبرداري شده_است گفتني نسخه DVD فيلم جشنواره نمايش داده '"
      ],
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      }
     },
     "metadata": {},
     "execution_count": 53
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# stop word\n",
    "stop_words_list = []\n",
    "with open('PersianStopWords.txt', \"rb\") as file:\n",
    "  for line in file:\n",
    "    stop_words_list.append(line.decode(\"UTF-8\").replace('\\r\\n', \"\"))\n",
    "\n",
    "for idx, txt in enumerate(df[\"Text\"]):\n",
    "  word_tokenized =  hazm.word_tokenize(txt)\n",
    "  cps = \"\"\n",
    "  for word in word_tokenized:\n",
    "    if word not in stop_words_list:\n",
    "      cps += word + \" \"\n",
    "      \n",
    "  df.loc[idx].at['Text'] = cps\n",
    "  if idx % 50000 == 0:\n",
    "    print(idx, \"numbers cleaned\")"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YaPjfG-LOoLd",
    "outputId": "5bc8f51b-99e8-4408-db00-8cdf43779f6d"
   },
   "execution_count": 60,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/pandas/core/series.py:1169: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._set_values(loc, value)\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0 numbers cleaned\n",
      "10000 numbers cleaned\n",
      "20000 numbers cleaned\n",
      "30000 numbers cleaned\n",
      "40000 numbers cleaned\n",
      "50000 numbers cleaned\n",
      "60000 numbers cleaned\n",
      "70000 numbers cleaned\n",
      "80000 numbers cleaned\n",
      "90000 numbers cleaned\n",
      "100000 numbers cleaned\n",
      "110000 numbers cleaned\n",
      "120000 numbers cleaned\n",
      "130000 numbers cleaned\n",
      "140000 numbers cleaned\n",
      "150000 numbers cleaned\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Normalization"
   ],
   "metadata": {
    "id": "KdfaVqDLWOhO"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "df['text_len_by_words'] = df['Text'].apply(lambda t: len(hazm.word_tokenize(t)))\n",
    "min_max_len = df[\"text_len_by_words\"].min(), df[\"text_len_by_words\"].max()\n",
    "print(f'Min: {min_max_len[0]} \\tMax: {min_max_len[1]}')"
   ],
   "metadata": {
    "id": "vCQmGwhSf_L7"
   },
   "execution_count": 67,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "def data_gl_than(data, less_than=100.0, greater_than=0.0, col='text_len_by_words'):\n",
    "    data_length = data[col].values\n",
    "\n",
    "    data_glt = sum([1 for length in data_length if greater_than < length <= less_than])\n",
    "\n",
    "    data_glt_rate = (data_glt / len(data_length)) * 100\n",
    "\n",
    "    print(f'Texts with word length of greater than {greater_than} and less than {less_than} includes {data_glt_rate:.2f}% of the whole!')"
   ],
   "metadata": {
    "id": "XAW8Sp9TgrIZ"
   },
   "execution_count": 69,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "minlim, maxlim = 10, 500\n",
    "data_gl_than(df, maxlim, minlim)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9Ovf1nRhguPC",
    "outputId": "ed89a544-00a4-43af-eb50-953cfb349de8"
   },
   "execution_count": 82,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Texts with word length of greater than 11 and less than 500 includes 99.89% of the whole!\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# remove comments with the length of fewer than three words\n",
    "df['text_len_by_words'] = df['text_len_by_words'].apply(lambda len_t: len_t if minlim <= len_t <= maxlim else None)\n",
    "df = df.dropna(subset=['text_len_by_words'])\n",
    "df = df.reset_index(drop=True)"
   ],
   "metadata": {
    "id": "SiU3cYVuSPVH"
   },
   "execution_count": 73,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "min_max_len = df[\"text_len_by_words\"].min(), df[\"text_len_by_words\"].max()\n",
    "print(f'Min: {min_max_len[0]} \\tMax: {min_max_len[1]}')"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fkJZgrBjmL3O",
    "outputId": "309d9a3c-7f00-44e3-f45e-8699b55bbfe5"
   },
   "execution_count": 81,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Min: 11.0 \tMax: 500.0\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "unique_cats = list(sorted(df['Cat'].unique()))\n",
    "print(f'We have #{len(unique_cats)}: {unique_cats}')"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "U3G300kXWhCV",
    "outputId": "2a83ea7b-684b-454d-ed78-992f65d4a6ae"
   },
   "execution_count": 83,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "We have #104: ['Adabh', 'Aeqts', 'Akhar', 'Busiw', 'Cinew', 'Cultw', 'Econo', 'Eqtes', 'Globa', 'Gozar', 'Kharj', 'Lifew', 'Musical', 'Newsp', 'Nnaft', 'Santj', 'Sciew', 'Shari', 'Siasi', 'Sporw', 'Theatre', 'Thought', 'abksh', 'adabh', 'adarman', 'aeqts', 'akhar', 'art', 'artw', 'axrooz', 'bankb', 'bazar', 'books', 'busiw', 'cartoon', 'cinama', 'cinew', 'city', 'cultw', 'donya', 'earth', 'econo', 'econw', 'ejtem', 'elmfa', 'elmif', 'eqtes', 'eqtsj', 'ertebat', 'erteg', 'gards', 'globa', 'gofgu', 'goftg', 'gozar', 'gqarn', 'gungn', 'hamln', 'havad', 'igozar', 'ikabar', 'imaqal', 'infor', 'intep', 'jjahn', 'jvarz', 'kharj', 'lastp', 'lifew', 'lite', 'maqal', 'maref', 'media', 'mohit', 'mskan', 'musical', 'nameh', 'newsp', 'nnaft', 'norooz', 'polig', 'sanat', 'santj', 'scien', 'sciew', 'shahr', 'shahz', 'shari', 'shora', 'shrst', 'siasi', 'socie', 'soxan', 'sport', 'sporw', 'techn', 'telfn', 'theatre', 'thought', 'vrzsh', 'women', 'ydsht', 'youth', 'zanan']\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "#Model loading"
   ],
   "metadata": {
    "id": "FfEsr4XoWZdO"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "model_repo = \"HooshvareLab/bert-fa-base-uncased-clf-persiannews\"\n",
    "config = AutoConfig.from_pretrained(model_repo)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_repo)\n",
    "model = AutoModel.from_pretrained(model_repo, num_labels=len(unique_cats))"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "T_TFJtz_MvZ3",
    "outputId": "f8aaed0a-5896-45f4-b1c0-8adf571d6fae"
   },
   "execution_count": 23,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Some weights of the model checkpoint at HooshvareLab/bert-fa-base-uncased-clf-persiannews were not used when initializing BertModel: ['classifier.weight', 'classifier.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "model.config.max_length = 20"
   ],
   "metadata": {
    "id": "ivwvpKpjhWLd"
   },
   "execution_count": 25,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "def preprocess_function(examples):\n",
    "    return tokenizer(examples, truncation=True)\n",
    "cf[\"Text\"].map(preprocess_function)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 200
    },
    "id": "jmKi8M-TrP-8",
    "outputId": "38c9a657-9fcb-4bdf-b2b9-8b1baf3b0c67"
   },
   "execution_count": 41,
   "outputs": [
    {
     "output_type": "error",
     "ename": "TypeError",
     "evalue": "ignored",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-41-8ab116e07aa0>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m()\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[0;32mdef\u001B[0m \u001B[0mpreprocess_function\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mexamples\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      2\u001B[0m     \u001B[0;32mreturn\u001B[0m \u001B[0mtokenizer\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mexamples\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mtruncation\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;32mTrue\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m----> 3\u001B[0;31m \u001B[0mcf\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;34m\"Text\"\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mmap\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mpreprocess_function\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mbatched\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;32mTrue\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[0;31mTypeError\u001B[0m: map() got an unexpected keyword argument 'batched'"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "len(tokenizer(cf[\"Text\"][10], truncation=True, padding=True)['input_ids'])"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eJV3_KHc7u3B",
    "outputId": "33953b59-dfdc-418f-a461-5f9a71a4f733"
   },
   "execution_count": 51,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "221"
      ]
     },
     "metadata": {},
     "execution_count": 51
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "cf[\"Text\"][0]"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 123
    },
    "id": "ncy9BVa06PfY",
    "outputId": "2c2d851d-dcd3-45d2-c4e5-e3c8c1cd2083"
   },
   "execution_count": 40,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'جاودانگي زندگي گروهي طريق هنر نگاهي نمايشگاه آثار هنري احمد طباطبايي موضوع آثار طباطبايي مورچگان باطن ظاهري انسانهاهستند هيبتي حشره تابلوهاي نقاشي نمايشگر گوشه زندگي مورچه ديده ايم سنگين خودرا دوش كشد راه خسته نتيجه آمدن حادثه اتفاقي دستش رها گريز خطر گذارد فرار ساعتي نقطه برمي گردد دوش كشيده نفس زنان عرق ريزان منزل رساند داند راه رفت مورچه استعداد غريزه عملي شروع پايان رساند داند نسل آينده مزاياي استفاده نمايد داستان درازي انتها پاياني ميليونها سال گذشته ميلياردها سال خواهد_گذشت وهمين برنامه ميليونها تجديد گفت سير حيات تكامل پايان ناپذير اسرار جهان پاياني بخواهيم چيز پايان ناپذير برسيم انتهايي نيست جايي رسيم كتاب مورچگان نوشته موريس مترلينگ مورچگان تابلوهاي نقاشي احمد طباطبايي جايگاه ويژه دارند نمايشگاهي آثار هنرمند اول 23 خرداد نگارخانه برگ برپا 36 اثر موضوع نمايش عمومي درآمد طباطبايي مدت 18 سالي نقاشي پردازد موضوع مورچگان كار علت انتخاب سوژه گويد روزهاي زندگي غمگين بودم زماني خواب رفتم مورچه ديدم تصميم گرفتم طرح بكشم كار نظرم جالب آمد روز طراحي ادامه دادم نقاشي مدلها تغييراتي ايجاد ضمن حشره دليل زندگي منظمي جذاب نظم اركان آثار نقاشي طباطبايي عليرغم موضوعات ساده تركيببندي دو بعدي تنوع كم رنگ آميزي سطوح استحكام طرحها نقوش پرده اثر نشان نظمي دروني نظم آناتومي اندام مورچگان نشان مشخصه اصلي مورچگان دست پا تقسيم بندي سه گانه بدن مهمتر آنكه شش دست پا راه روند نقاشيهاي طباطبايي دو پا انسان ايستند سرهايشان بزرگترين اندام بدنشان چشمها طور اغراق آميزي سرجا گرفته_است هدف نقاش تغييرات اندام مورچگان باآنكه نقاش گفته نقاشيها استنباط موضوع آثار طباطبايي مورچگان باطن ظاهري انسانها هيبتي حشره تابلوهاي نقاش نمايشگر گوشه زندگي اندام سياه زمينه خاكستري بادكنكهاي رنگي دست دارند عروسي تغيير اندام مورچگان باعث چهره حالات صورت اندام بازگو كننده احساسات موضوع تابلوي نقاشي نباشد بدن مورچه انسانهاحسي پديد آورند تابلو سايه اندازد احساساتي دام افتادن دام عنكبوت مادري كردن تفاهم دوستي نكته نقاشي درختان صورت اسليمي ايراني حاشيه تابلوها خطوط رنگهايي زنده شاداب نقشها تقابل بصري مورچه انسانهاست هماهنگي دروني مفهوم مورچه انسانها تصوير كشيده شده_اند رنگهاي شاد سبز ميوه سرخ شكل انساني محيط افزايش دهند مورچگان طور گروهي فضا برند اصل دانند; جاودانگي زندگي گروهي انتقال احساسات طريق هنر راهي مترلينگ اشاره كرد '"
      ],
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      }
     },
     "metadata": {},
     "execution_count": 40
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    ""
   ],
   "metadata": {
    "id": "przc5RaQ6mYu"
   },
   "execution_count": null,
   "outputs": []
  }
 ]
}